{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1>Brain Tumor Detection ðŸ§ </h1><center>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://images.unsplash.com/photo-1559757175-0eb30cd8c063?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1031&q=80\">","metadata":{}},{"cell_type":"markdown","source":"# Importing Essential Libraries and Tools","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntf.keras.backend.clear_session()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-08-22T11:44:24.467398Z","iopub.execute_input":"2022-08-22T11:44:24.468256Z","iopub.status.idle":"2022-08-22T11:44:24.490208Z","shell.execute_reply.started":"2022-08-22T11:44:24.468187Z","shell.execute_reply":"2022-08-22T11:44:24.489041Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Data","metadata":{}},{"cell_type":"markdown","source":"We load the data by making use of the tool image_dataset_from directory. It helps us fetch the data from the relevant directory, automatically does labeling, shuffles the data, batches the data (in this case as 32) and resizes images into 256 by 256.","metadata":{}},{"cell_type":"code","source":"data = keras.utils.image_dataset_from_directory(\"../input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset\")","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:24.495840Z","iopub.execute_input":"2022-08-22T11:44:24.496755Z","iopub.status.idle":"2022-08-22T11:44:24.625500Z","shell.execute_reply.started":"2022-08-22T11:44:24.496706Z","shell.execute_reply":"2022-08-22T11:44:24.624219Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"<h3>Plotting a few Example Images</h3>","metadata":{}},{"cell_type":"markdown","source":"If a brain has tumor it is labeled as 1, if no it is labeled as 0.","metadata":{}},{"cell_type":"code","source":"batch = data.as_numpy_iterator().next()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-22T11:44:24.627237Z","iopub.execute_input":"2022-08-22T11:44:24.628261Z","iopub.status.idle":"2022-08-22T11:44:25.266020Z","shell.execute_reply.started":"2022-08-22T11:44:24.628210Z","shell.execute_reply":"2022-08-22T11:44:25.264720Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 5, figsize=(15,10))\nax = ax.flatten()\nfor idx, img in enumerate(batch[0][:15]):\n    ax[idx].imshow(img.astype(int))\n    ax[idx].title.set_text(batch[1][idx])","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:25.267738Z","iopub.execute_input":"2022-08-22T11:44:25.268271Z","iopub.status.idle":"2022-08-22T11:44:26.986396Z","shell.execute_reply.started":"2022-08-22T11:44:25.268221Z","shell.execute_reply":"2022-08-22T11:44:26.985219Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Data Scaling","metadata":{}},{"cell_type":"markdown","source":"Since our data consists of images and images consist of pixels, we divide all the pixel values by 255â€”each pixel can have a value in [0, 255]â€” so that all the pixel values are on the same scale i.e. [0, 1].","metadata":{}},{"cell_type":"code","source":"data = data.map(lambda x,y: (x/255, y))","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:26.989882Z","iopub.execute_input":"2022-08-22T11:44:26.990883Z","iopub.status.idle":"2022-08-22T11:44:27.004761Z","shell.execute_reply.started":"2022-08-22T11:44:26.990838Z","shell.execute_reply":"2022-08-22T11:44:27.003692Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"batch = data.as_numpy_iterator().next()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-22T11:44:27.006490Z","iopub.execute_input":"2022-08-22T11:44:27.007534Z","iopub.status.idle":"2022-08-22T11:44:27.319036Z","shell.execute_reply.started":"2022-08-22T11:44:27.007492Z","shell.execute_reply":"2022-08-22T11:44:27.318170Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(\"Minimum value of the scaled data:\", batch[0].min())\nprint(\"Maximum value of the scaled data:\", batch[0].max())","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:27.320225Z","iopub.execute_input":"2022-08-22T11:44:27.320558Z","iopub.status.idle":"2022-08-22T11:44:27.330929Z","shell.execute_reply.started":"2022-08-22T11:44:27.320527Z","shell.execute_reply":"2022-08-22T11:44:27.329817Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Train-Validation-Test Split","metadata":{}},{"cell_type":"code","source":"print(\"There are\", len(data), \"batches in our data\")","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:27.332232Z","iopub.execute_input":"2022-08-22T11:44:27.333043Z","iopub.status.idle":"2022-08-22T11:44:27.340005Z","shell.execute_reply.started":"2022-08-22T11:44:27.333006Z","shell.execute_reply":"2022-08-22T11:44:27.339221Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Now, we have to divide the whole data into 3 separate sets: Train set for training the model, Validation set for adjusting the hyperparameters of our model and Test set for evaluating our model on the set that our model has not seen before. As it can be seen, we have 8 batches in our data. I preferred allocating 4 batches for Train set, 2 batches for Validation set and 2 batches for Test set.","metadata":{}},{"cell_type":"code","source":"train_size = int(len(data)*0.6)\nval_size = int(len(data)*0.2)+1\ntest_size = int(len(data)*0.2)+1","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:27.341676Z","iopub.execute_input":"2022-08-22T11:44:27.342335Z","iopub.status.idle":"2022-08-22T11:44:27.352366Z","shell.execute_reply.started":"2022-08-22T11:44:27.342298Z","shell.execute_reply":"2022-08-22T11:44:27.351350Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(\"Train Size:\", train_size)\nprint(\"Validation Size:\", val_size)\nprint(\"Test Size:\", test_size)\n\nprint(\"Sum of Train, Validation and Test sizes is equal to:\", train_size + val_size + test_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:27.354096Z","iopub.execute_input":"2022-08-22T11:44:27.354814Z","iopub.status.idle":"2022-08-22T11:44:27.364628Z","shell.execute_reply.started":"2022-08-22T11:44:27.354777Z","shell.execute_reply":"2022-08-22T11:44:27.363567Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train = data.take(train_size)\nval = data.skip(train_size).take(val_size)\ntest = data.skip(train_size + val_size).take(test_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:27.366305Z","iopub.execute_input":"2022-08-22T11:44:27.367151Z","iopub.status.idle":"2022-08-22T11:44:27.377979Z","shell.execute_reply.started":"2022-08-22T11:44:27.367090Z","shell.execute_reply":"2022-08-22T11:44:27.376672Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"Because our Train set has relatively small number of images, we can apply data augmentation which is reproducing the images by applying some changes such as random rotating, random flipping, random zoom and random contrast. This may possibly increase the accuracy score of the model. Since we will be applying the data augmentation in the beginning of the neural network architecture, we should pass the input shape.\n\nNote: Data augmentation will be inactive when testing the data. Input images will be augmented during calls to model.fit (not model.evaluate or model.predict). If you want to learn more about data augmentation in Tensorflow, you can check the official documentation.","metadata":{}},{"cell_type":"code","source":"batch = data.as_numpy_iterator().next()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-22T11:44:27.380353Z","iopub.execute_input":"2022-08-22T11:44:27.381258Z","iopub.status.idle":"2022-08-22T11:44:27.701169Z","shell.execute_reply.started":"2022-08-22T11:44:27.381211Z","shell.execute_reply":"2022-08-22T11:44:27.699863Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"data_augmentation = Sequential([\n    layers.RandomFlip(\"horizontal_and_vertical\", input_shape=(256,256,3)),\n    layers.RandomZoom(0.1),\n    layers.RandomContrast(0.1),\n    layers.RandomRotation(0.2)\n])\n\nimage = batch[0]\n\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    augmented_image = data_augmentation(image)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_image[0])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:27.703499Z","iopub.execute_input":"2022-08-22T11:44:27.703880Z","iopub.status.idle":"2022-08-22T11:44:30.410136Z","shell.execute_reply.started":"2022-08-22T11:44:27.703846Z","shell.execute_reply":"2022-08-22T11:44:30.408989Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Building Deep Learning Model","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    data_augmentation,\n    Conv2D(16, (3,3), 1, activation=\"relu\", padding=\"same\"),\n    Conv2D(16, (3,3), 1, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(),\n    Conv2D(32, (5,5), 1, activation=\"relu\", padding=\"same\"),\n    Conv2D(32, (5,5), 1, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(),\n    Conv2D(16, (3,3), 1, activation=\"relu\", padding=\"same\"),\n    Conv2D(16, (3,3), 1, activation=\"relu\", padding=\"same\"),\n    MaxPooling2D(),\n    \n    Flatten(),\n    Dense(128, activation=\"relu\"),\n    Dense(1, activation=\"sigmoid\")\n])","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:30.414518Z","iopub.execute_input":"2022-08-22T11:44:30.415008Z","iopub.status.idle":"2022-08-22T11:44:30.693897Z","shell.execute_reply.started":"2022-08-22T11:44:30.414968Z","shell.execute_reply":"2022-08-22T11:44:30.692500Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:30.695572Z","iopub.execute_input":"2022-08-22T11:44:30.696032Z","iopub.status.idle":"2022-08-22T11:44:30.710580Z","shell.execute_reply.started":"2022-08-22T11:44:30.695989Z","shell.execute_reply":"2022-08-22T11:44:30.709213Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:44:30.712652Z","iopub.execute_input":"2022-08-22T11:44:30.713490Z","iopub.status.idle":"2022-08-22T11:44:30.723261Z","shell.execute_reply.started":"2022-08-22T11:44:30.713428Z","shell.execute_reply":"2022-08-22T11:44:30.721888Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train, epochs=15, validation_data=val)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-22T11:44:30.725276Z","iopub.execute_input":"2022-08-22T11:44:30.726060Z","iopub.status.idle":"2022-08-22T11:46:47.293179Z","shell.execute_reply.started":"2022-08-22T11:44:30.726018Z","shell.execute_reply":"2022-08-22T11:46:47.292174Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Plotting the Performance","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(10,8))\n\nax[0].plot(history.history[\"loss\"], label=\"Train\")\nax[0].plot(history.history[\"val_loss\"], label=\"Validation\")\nax[0].title.set_text(\"Loss\")\nax[0].legend()\n\nax[1].plot(history.history[\"accuracy\"], label=\"Train\")\nax[1].plot(history.history[\"val_accuracy\"], label=\"Validation\")\nax[1].title.set_text(\"Accuracy\")\nax[1].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:46:47.295106Z","iopub.execute_input":"2022-08-22T11:46:47.296220Z","iopub.status.idle":"2022-08-22T11:46:47.671466Z","shell.execute_reply.started":"2022-08-22T11:46:47.296158Z","shell.execute_reply":"2022-08-22T11:46:47.670071Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"bin_acc = BinaryAccuracy()\nrecall = Recall()\nprecision = Precision()\n\nfor batch in test.as_numpy_iterator():\n    X, y = batch\n    yhat = model.predict(X)\n    bin_acc.update_state(y, yhat)\n    recall.update_state(y, yhat)\n    precision.update_state(y, yhat)\n\nprint(\"Accuracy:\", bin_acc.result().numpy(), \"\\nRecall:\", recall.result().numpy(), \"\\nPrecision:\", precision.result().numpy())","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:46:47.673492Z","iopub.execute_input":"2022-08-22T11:46:47.673902Z","iopub.status.idle":"2022-08-22T11:46:50.256062Z","shell.execute_reply.started":"2022-08-22T11:46:47.673866Z","shell.execute_reply":"2022-08-22T11:46:50.254702Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# Manual Testing","metadata":{}},{"cell_type":"markdown","source":"We have already evaluated our model using various metrics and visualizations but it is always a good practice to test the model by hand to make sure everything is working well. In the code below, I randomly chose an image and plotted it with its true label on title so let's see if our model is going to classify this example correctly.","metadata":{}},{"cell_type":"code","source":"batch = test.as_numpy_iterator().next()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-22T11:46:50.257569Z","iopub.execute_input":"2022-08-22T11:46:50.257941Z","iopub.status.idle":"2022-08-22T11:46:50.612585Z","shell.execute_reply.started":"2022-08-22T11:46:50.257909Z","shell.execute_reply":"2022-08-22T11:46:50.610889Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"img, label = batch[0][15], batch[1][15]\nplt.imshow(img)\nif label==1:\n    plt.title(\"Brain with Tumor\")\nelse:\n    plt.title(\"Brain with No Tumor\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:46:50.614474Z","iopub.execute_input":"2022-08-22T11:46:50.614983Z","iopub.status.idle":"2022-08-22T11:46:50.847027Z","shell.execute_reply.started":"2022-08-22T11:46:50.614946Z","shell.execute_reply":"2022-08-22T11:46:50.845896Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"y_hat = model.predict(np.expand_dims(img, 0))","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:46:50.848698Z","iopub.execute_input":"2022-08-22T11:46:50.849534Z","iopub.status.idle":"2022-08-22T11:46:50.932019Z","shell.execute_reply.started":"2022-08-22T11:46:50.849484Z","shell.execute_reply":"2022-08-22T11:46:50.930614Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"We are able to see the probability of this brain's having tumor below. I opted to determine the classification threshold as 0.5. Meaning that, if it is below 0.5 this will be classified as Brain Having No Tumor otherwise it is going to be classified as Brain Having Tumor.","metadata":{}},{"cell_type":"code","source":"y_hat","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:46:50.934029Z","iopub.execute_input":"2022-08-22T11:46:50.934685Z","iopub.status.idle":"2022-08-22T11:46:50.942788Z","shell.execute_reply.started":"2022-08-22T11:46:50.934643Z","shell.execute_reply":"2022-08-22T11:46:50.941893Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"if y_hat < 0.5:\n    print(\"No tumor detected\")\nelse:\n    print(\"Tumor detected\")","metadata":{"execution":{"iopub.status.busy":"2022-08-22T11:46:50.944178Z","iopub.execute_input":"2022-08-22T11:46:50.945220Z","iopub.status.idle":"2022-08-22T11:46:50.954501Z","shell.execute_reply.started":"2022-08-22T11:46:50.945180Z","shell.execute_reply":"2022-08-22T11:46:50.953114Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Here we can see that our model predicted its class correctly.","metadata":{}}]}